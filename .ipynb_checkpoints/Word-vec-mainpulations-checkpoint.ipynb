{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed3969db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b9c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\", errors='ignore') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc32b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words = 400000\n",
      "Length of w2v_map = 400000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "words, w2v_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "print(f'Length of words = {len(words)}')\n",
    "print(f'Length of w2v_map = {len(w2v_map)}')\n",
    "\n",
    "#Verifying each word has a corresponding vector and a proper vector\n",
    "cnt = 0\n",
    "for i in w2v_map.keys():\n",
    "    if i not in words and len(w2v_map[i]) == 50:\n",
    "        print(f'Error!!! Word {i} is not in words')\n",
    "    else:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e898cdc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_items' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ASHISH~1\\AppData\\Local\\Temp/ipykernel_424/3790869053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_items' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "n = len(w2v_map)\n",
    "json1 = {word: w2v_map[word] for word in words[:n//2]}\n",
    "json2= {word: w2v_map[word] for word in words[n//2:]}\n",
    "\n",
    "print(f'Length of afdassa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(word1, word2):\n",
    "    u = w2v_map[word1]\n",
    "    v = w2v_map[word2]\n",
    "    \n",
    "    if np.all(u == v):\n",
    "        return 1\n",
    "    \n",
    "    dot = np.dot(u.T, v)\n",
    "    mod_u = np.sum(np.dot(u.T, u))\n",
    "    mod_v = np.sum(np.dot(v.T, v))\n",
    "    \n",
    "    if mod_u * mod_v == 0:\n",
    "        return 0\n",
    "    return dot / (mod_u * mod_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the cosine similarities\n",
    "Examples = [('india', 'no'), ('no', 'not'), ('affirmative', 'yes'), ('yes', 'yes')]\n",
    "for a,b in Examples:\n",
    "    if a in words and b in words:\n",
    "        print(f'Cosine similarity [{a} : {b}] = {cosine_similarity(a, b)} ({cosine_similarity(b, a)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(word1, word2, word3):\n",
    "    if word1 not in words or word2 not in words or word3 not in words:\n",
    "        return 'NULL'\n",
    "    \n",
    "    u = w2v_map[word1]\n",
    "    v = w2v_map[word2]\n",
    "    p = w2v_map[word3]\n",
    "    #q = ?\n",
    "    \n",
    "    q = ''\n",
    "    mn = -1000\n",
    "    for word in words:\n",
    "        sim = cosine_similarity(v - u, w2v_map[word] - p)\n",
    "        if sim < mn:\n",
    "            mn = sim\n",
    "            q = word\n",
    "    return q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65766917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing analogies of the model\n",
    "triads_to_try = [('india', 'delhi', 'japan')]\n",
    "for a,b,c in triads_to_try:\n",
    "    print(f'{a}:{b} :: {c}:{analogy(a, b, c)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb1792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf4dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
